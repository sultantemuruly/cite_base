import json
from typing import Annotated, Any
from dotenv import load_dotenv
from IPython.display import Markdown, display

from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.types import Command
from langchain_core.messages import HumanMessage, SystemMessage

from agents.retrieval_orchestrator_agent import (
    create_retrieval_orchestrator_agent,
    Context,
)
from agents.resoning_agent import create_reasoning_agent
from utils.file_io import read_markdown_file

load_dotenv()


class MainState(MessagesState):
    question: Annotated[str, "The user's question"]
    retrieval_results: Annotated[
        dict | None, "The retrieval results from the retrieval orchestrator agent"
    ] = None
    final_answer: Annotated[
        str | None, "The final answer generated by the reasoning agent"
    ] = None
    human_approval: Annotated[
        bool | None, "Whether the human approved the final answer"
    ] = None
    rag_chain: Annotated[Any, "The RAG chain to use for retrieval"]
    pending_review: Annotated[
        Any | None, "HITL review configs returned on interrupt"
    ] = None


retrieval_orchestrator_agent = create_retrieval_orchestrator_agent()
reasoning_agent = create_reasoning_agent()
reasoning_prompt = read_markdown_file("../prompts/reasoning_prompt.md")


def invoke_retrieval_orchestration(state: MainState):
    """Invoke the retrieval orchestrator agent to get context from RAG."""
    # Get the user question from state or last message
    user_question = state.get("question") or (
        state.get("messages", [])[-1].content if state.get("messages") else None
    )
    if not user_question:
        raise ValueError("No question found in state")

    # Get rag_chain from state
    rag_chain = state.get("rag_chain")
    if not rag_chain:
        raise ValueError("No rag_chain found in state")

    result = retrieval_orchestrator_agent.invoke(
        {
            "messages": [{"role": "user", "content": user_question}],
        },
        context=Context(rag_chain=rag_chain),
    )
    res_messages = result["messages"]
    retrieval_results = result["structured_response"]["results"]
    return {
        "messages": res_messages,
        "retrieval_results": retrieval_results,
        "question": user_question,  # Ensure question is set in state
    }


def invoke_reasoning(state: MainState):
    """Invoke the reasoning agent with retrieval results."""
    # Get question and retrieval results from state
    user_question = state.get("question") or (
        state.get("messages", [])[-1].content if state.get("messages") else None
    )
    if not user_question:
        raise ValueError("No question found in state")

    retrieval_results = state.get("retrieval_results")
    if not retrieval_results:
        raise ValueError("No retrieval results found in state")

    # Format the reasoning prompt with user question and context
    formatted_prompt = reasoning_prompt.format(
        user_question=user_question, context=json.dumps(retrieval_results, indent=2)
    )

    # Create messages with system prompt and user question
    messages = [
        SystemMessage(content=formatted_prompt),
        HumanMessage(content=user_question),
    ]

    cfg = {"configurable": {"thread_id": "reasoning-thread"}}

    result = reasoning_agent.invoke({"messages": messages}, config=cfg)
    res_messages = result["messages"]

    # If the agent interrupted for HITL, store review configs; graph edges decide routing
    if "__interrupt__" in result:
        review_configs = result["__interrupt__"][-1].value["review_configs"]
        return {"messages": res_messages, "pending_review": review_configs}

    # Extract final answer from structured response
    final_answer = result.get("structured_response", {}).get("final_answer", "")
    if not final_answer:
        # Fallback: get from last message if structured response is missing
        final_answer = res_messages[-1].content if res_messages else ""

    return {
        "messages": res_messages,
        "final_answer": final_answer,
        "pending_review": None,
    }


def human_review(state: MainState):
    """Handle human review for web search approval."""
    # Present state.pending_review to a human and collect decision.
    # For now, auto-approve to demonstrate resume flow.
    pending_review = state.get("pending_review")
    print("Human review needed for web search approval.")
    print(f"Pending review: {pending_review}")

    decision = {
        "type": "approve"
    }  # Auto-approve for demo; later will replace with user input
    cfg = {"configurable": {"thread_id": "reasoning-thread"}}

    resumed = reasoning_agent.invoke(
        Command(resume={"decisions": [decision]}),
        config=cfg,
    )

    res_messages = resumed["messages"]

    # Extract final answer from structured response
    final_answer = resumed.get("structured_response", {}).get("final_answer", "")
    if not final_answer:
        # Fallback: get from last message if structured response is missing
        final_answer = res_messages[-1].content if res_messages else ""

    # Graph-directed: only update; builder edge sends us to END
    return {
        "messages": res_messages,
        "final_answer": final_answer,
        "human_approval": True,
        "pending_review": None,
    }


def create_orchestration_graph():
    """Create and return the compiled orchestration graph."""
    builder = StateGraph(MainState)

    # Add nodes
    builder.add_node("invoke_retrieval_orchestration", invoke_retrieval_orchestration)
    builder.add_node("invoke_reasoning", invoke_reasoning)
    builder.add_node("human_review", human_review)

    # Add edges
    builder.add_edge(START, "invoke_retrieval_orchestration")
    builder.add_edge("invoke_retrieval_orchestration", "invoke_reasoning")

    # Route based on presence of pending_review set by invoke_reasoning
    def should_review(state: MainState) -> str:
        """Determine if human review is needed."""
        pending = state.get("pending_review")
        if pending is not None:
            return "human_review"
        return "end"

    builder.add_conditional_edges(
        "invoke_reasoning",
        should_review,
        {
            "human_review": "human_review",
            "end": END,
        },
    )

    builder.add_edge("human_review", END)

    return builder.compile()


# Default instance for convenience
graph = create_orchestration_graph()
