{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c29f55ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ensure project root is on sys.path for absolute imports\n",
        "import os, sys\n",
        "project_root = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
        "if project_root not in sys.path:\n",
        "    sys.path.insert(0, project_root)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3044d229",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8be0830e",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
            "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
          ]
        }
      ],
      "source": [
        "from agents.rag_ingest import initialize_vectorstore_with_rag_chain\n",
        "from pathlib import Path\n",
        "from tempfile import mkdtemp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "69c3a270",
      "metadata": {},
      "outputs": [],
      "source": [
        "FILE_PATH = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
        "TOP_K = 3\n",
        "milvus_uri = str(Path(mkdtemp()) / \"vector.db\")\n",
        "collection_name=\"vectordb\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9c44555f",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 01:24:02,300 - INFO - detected formats: [<InputFormat.PDF: 'pdf'>]\n",
            "2026-01-09 01:24:02,388 - INFO - Going to convert document batch...\n",
            "2026-01-09 01:24:02,389 - INFO - Initializing pipeline for StandardPdfPipeline with options hash e15bc6f248154cc62f8db15ef18a8ab7\n",
            "2026-01-09 01:24:02,397 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
            "2026-01-09 01:24:02,398 - INFO - Loading plugin 'docling_defaults'\n",
            "2026-01-09 01:24:02,400 - INFO - Registered picture descriptions: ['vlm', 'api']\n",
            "2026-01-09 01:24:02,406 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
            "2026-01-09 01:24:02,406 - INFO - Loading plugin 'docling_defaults'\n",
            "2026-01-09 01:24:02,410 - INFO - Registered ocr engines: ['auto', 'easyocr', 'ocrmac', 'rapidocr', 'tesserocr', 'tesseract']\n",
            "2026-01-09 01:24:03,173 - INFO - Auto OCR model selected ocrmac.\n",
            "2026-01-09 01:24:03,180 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
            "2026-01-09 01:24:03,180 - INFO - Loading plugin 'docling_defaults'\n",
            "2026-01-09 01:24:03,183 - INFO - Registered layout engines: ['docling_layout_default', 'docling_experimental_table_crops_layout']\n",
            "2026-01-09 01:24:03,186 - INFO - Accelerator device: 'mps'\n",
            "2026-01-09 01:24:04,753 - WARNING - The plugin langchain_docling will not be loaded because Docling is being executed with allow_external_plugins=false.\n",
            "2026-01-09 01:24:04,754 - INFO - Loading plugin 'docling_defaults'\n",
            "2026-01-09 01:24:04,755 - INFO - Registered table structure engines: ['docling_tableformer']\n",
            "2026-01-09 01:24:05,254 - INFO - Accelerator device: 'mps'\n",
            "2026-01-09 01:24:06,081 - INFO - Processing document NIPS-2017-attention-is-all-you-need-Paper.pdf\n",
            "2026-01-09 01:24:19,426 - INFO - Finished converting document NIPS-2017-attention-is-all-you-need-Paper.pdf in 19.90 sec.\n",
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/milvus_lite/__init__.py:15: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
            "  from pkg_resources import DistributionNotFound, get_distribution\n",
            "2026-01-09 01:24:23,277 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
          ]
        }
      ],
      "source": [
        "rag_chain = initialize_vectorstore_with_rag_chain(\n",
        "    FILE_PATH=FILE_PATH,\n",
        "    TOP_K=TOP_K,\n",
        "    milvus_uri=milvus_uri,\n",
        "    collection_name=collection_name,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9c45a9f0",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/langchain_tavily/tavily_research.py:97: UserWarning: Field name \"output_schema\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
            "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n",
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/langchain_tavily/tavily_research.py:97: UserWarning: Field name \"stream\" in \"TavilyResearch\" shadows an attribute in parent \"BaseTool\"\n",
            "  class TavilyResearch(BaseTool):  # type: ignore[override, override]\n"
          ]
        }
      ],
      "source": [
        "from agents.retrieval_orchestrator_agent import create_retrieval_orchestrator_agent, Context\n",
        "from agents.resoning_agent import create_reasoning_agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "3a271225",
      "metadata": {},
      "outputs": [],
      "source": [
        "retrieval_orchestrator_agent = create_retrieval_orchestrator_agent()\n",
        "reasoning_agent = create_reasoning_agent()\n",
        "\n",
        "# Load reasoning prompt for dynamic formatting\n",
        "def read_markdown_file(filepath):\n",
        "    \"\"\"Reads the content of a Markdown file as a string.\"\"\"\n",
        "    try:\n",
        "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
        "            text = f.read()\n",
        "        return text\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: The file at {filepath} was not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"An error occurred: {e}\"\n",
        "\n",
        "reasoning_prompt = read_markdown_file(\"../prompts/reasoning_prompt.md\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "29135202",
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, MessagesState, START, END\n",
        "from langgraph.types import Command\n",
        "from typing import Annotated, Any\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "5be22bd2",
      "metadata": {},
      "outputs": [],
      "source": [
        "class MainState(MessagesState):\n",
        "    question: Annotated[str, \"The user's question\"]\n",
        "    retrieval_results: Annotated[dict | None, \"The retrieval results from the retrieval orchestrator agent\"] = None\n",
        "    final_answer: Annotated[str | None, \"The final answer generated by the reasoning agent\"] = None\n",
        "    human_approval: Annotated[bool | None, \"Whether the human approved the final answer\"] = None\n",
        "    rag_chain: Annotated[Any, \"The RAG chain to use for retrieval\"]\n",
        "    pending_review: Annotated[Any | None, \"HITL review configs returned on interrupt\"] = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e28ebfb1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def invoke_retrieval_orchestration(state: MainState):\n",
        "    \"\"\"Invoke the retrieval orchestrator agent to get context from RAG.\"\"\"\n",
        "    # Get the user question from state or last message\n",
        "    user_question = state.get(\"question\") or (state.get(\"messages\", [])[-1].content if state.get(\"messages\") else None)\n",
        "    if not user_question:\n",
        "        raise ValueError(\"No question found in state\")\n",
        "    \n",
        "    # Get rag_chain from state\n",
        "    rag_chain = state.get(\"rag_chain\")\n",
        "    if not rag_chain:\n",
        "        raise ValueError(\"No rag_chain found in state\")\n",
        "    \n",
        "    result = retrieval_orchestrator_agent.invoke(\n",
        "        {\n",
        "            \"messages\": [\n",
        "                {\"role\": \"user\", \"content\": user_question}\n",
        "            ],\n",
        "        },\n",
        "        context=Context(rag_chain=rag_chain)\n",
        "    )\n",
        "    res_messages = result[\"messages\"]\n",
        "    retrieval_results = result[\"structured_response\"][\"results\"]\n",
        "    return {\n",
        "        \"messages\": res_messages, \n",
        "        \"retrieval_results\": retrieval_results,\n",
        "        \"question\": user_question  # Ensure question is set in state\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "6104c191",
      "metadata": {},
      "outputs": [],
      "source": [
        "def invoke_reasoning(state: MainState):\n",
        "    \"\"\"Invoke the reasoning agent with retrieval results.\"\"\"\n",
        "    # Get question and retrieval results from state\n",
        "    user_question = state.get(\"question\") or (state.get(\"messages\", [])[-1].content if state.get(\"messages\") else None)\n",
        "    if not user_question:\n",
        "        raise ValueError(\"No question found in state\")\n",
        "    \n",
        "    retrieval_results = state.get(\"retrieval_results\")\n",
        "    if not retrieval_results:\n",
        "        raise ValueError(\"No retrieval results found in state\")\n",
        "    \n",
        "    # Format the reasoning prompt with user question and context\n",
        "    formatted_prompt = reasoning_prompt.format(\n",
        "        user_question=user_question, \n",
        "        context=json.dumps(retrieval_results, indent=2)\n",
        "    )\n",
        "    \n",
        "    # Create messages with system prompt and user question\n",
        "    messages = [\n",
        "        SystemMessage(content=formatted_prompt),\n",
        "        HumanMessage(content=user_question)\n",
        "    ]\n",
        "    \n",
        "    cfg = {\"configurable\": {\"thread_id\": \"reasoning-thread\"}}\n",
        "\n",
        "    result = reasoning_agent.invoke({\"messages\": messages}, config=cfg)\n",
        "    res_messages = result[\"messages\"]\n",
        "\n",
        "    # If the agent interrupted for HITL, store review configs; graph edges decide routing\n",
        "    if \"__interrupt__\" in result:\n",
        "        review_configs = result[\"__interrupt__\"][-1].value[\"review_configs\"]\n",
        "        return {\"messages\": res_messages, \"pending_review\": review_configs}\n",
        "\n",
        "    # Extract final answer from structured response\n",
        "    final_answer = result.get(\"structured_response\", {}).get(\"final_answer\", \"\")\n",
        "    if not final_answer:\n",
        "        # Fallback: get from last message if structured response is missing\n",
        "        final_answer = res_messages[-1].content if res_messages else \"\"\n",
        "    \n",
        "    return {\n",
        "        \"messages\": res_messages, \n",
        "        \"final_answer\": final_answer, \n",
        "        \"pending_review\": None\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d76b8438",
      "metadata": {},
      "outputs": [],
      "source": [
        "def human_review(state: MainState):\n",
        "    \"\"\"Handle human review for web search approval.\"\"\"\n",
        "    # Present state.pending_review to a human and collect decision.\n",
        "    # For now, auto-approve to demonstrate resume flow.\n",
        "    pending_review = state.get(\"pending_review\")\n",
        "    print(\"Human review needed for web search approval.\")\n",
        "    print(f\"Pending review: {pending_review}\")\n",
        "    \n",
        "    decision = {\"type\": \"approve\"}  # Auto-approve for demo; later will replace with user input\n",
        "    cfg = {\"configurable\": {\"thread_id\": \"reasoning-thread\"}}\n",
        "\n",
        "    resumed = reasoning_agent.invoke(\n",
        "        Command(resume={\"decisions\": [decision]}),\n",
        "        config=cfg,\n",
        "    )\n",
        "\n",
        "    res_messages = resumed[\"messages\"]\n",
        "    \n",
        "    # Extract final answer from structured response\n",
        "    final_answer = resumed.get(\"structured_response\", {}).get(\"final_answer\", \"\")\n",
        "    if not final_answer:\n",
        "        # Fallback: get from last message if structured response is missing\n",
        "        final_answer = res_messages[-1].content if res_messages else \"\"\n",
        "\n",
        "    # Graph-directed: only update; builder edge sends us to END\n",
        "    return {\n",
        "        \"messages\": res_messages,\n",
        "        \"final_answer\": final_answer,\n",
        "        \"human_approval\": True,\n",
        "        \"pending_review\": None,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4199c7a7",
      "metadata": {},
      "outputs": [],
      "source": [
        "builder = StateGraph(MainState)\n",
        "\n",
        "builder.add_node(\"invoke_retrieval_orchestration\", invoke_retrieval_orchestration)\n",
        "builder.add_node(\"invoke_reasoning\", invoke_reasoning)\n",
        "builder.add_node(\"human_review\", human_review)\n",
        "\n",
        "builder.add_edge(START, \"invoke_retrieval_orchestration\")\n",
        "builder.add_edge(\"invoke_retrieval_orchestration\", \"invoke_reasoning\")\n",
        "\n",
        "# Route based on presence of pending_review set by invoke_reasoning\n",
        "def should_review(state: MainState) -> str:\n",
        "    \"\"\"Determine if human review is needed.\"\"\"\n",
        "    pending = state.get(\"pending_review\")\n",
        "    if pending is not None:\n",
        "        return \"human_review\"\n",
        "    return \"end\"\n",
        "\n",
        "builder.add_conditional_edges(\n",
        "    \"invoke_reasoning\",\n",
        "    should_review,\n",
        "    {\n",
        "        \"human_review\": \"human_review\",\n",
        "        \"end\": END,\n",
        "    }\n",
        ")\n",
        "\n",
        "builder.add_edge(\"human_review\", END)\n",
        "\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48db8118",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026-01-09 01:24:31,057 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=Context(rag_chain=Runnabl...}, config_factories=[])), input_type=Context])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "2026-01-09 01:24:32,526 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:35,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "/Users/sultan/Projects/citebase/agents/.venv/lib/python3.14/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `none` - serialized value may not be as expected [field_name='context', input_value=Context(rag_chain=Runnabl...}, config_factories=[])), input_type=Context])\n",
            "  return self.__pydantic_serializer__.to_python(\n",
            "2026-01-09 01:24:37,099 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:38,657 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:46,696 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:47,868 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:54,912 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:24:56,374 - INFO - HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:25:03,899 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:25:33,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:25:52,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
            "2026-01-09 01:26:02,370 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "FINAL ANSWER:\n",
            "================================================================================\n",
            "The Transformer model operates primarily through attention mechanisms, which are utilized in three main ways: \\n1. **Encoder-decoder attention**: This allows the decoder to focus on different parts of the input sequence when generating outputs. \\n2. **Self-attention in the encoder**: This enables the model to weigh the significance of different words in the input for better representation. \\n3. **Self-attention in the decoder**: Similar to the encoder, this helps the decoder understand the context from the previously generated words in the output sequence. \\n\\nThe architecture consists of an encoder-decoder structure. The encoder comprises a stack of six identical layers, and each layer includes a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The decoder also has six layers but includes an additional attention layer for encoder-decoder attention. Both the encoder and decoder use residual connections and layer normalization, facilitating effective training and faster convergence. \\n\\nTransformers excel at sequence transduction tasks, such as machine translation, due to their ability to process sequences in parallel, effectively handling long-range dependencies, and outperforming traditional Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) in these applications. \n",
            "\n",
            "For detailed insights, refer to the paper \"Attention Is All You Need\" [source](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf).\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "user_question = \"How does the transformer model work?\"\n",
        "\n",
        "initial_state = {\n",
        "    \"messages\": [HumanMessage(content=user_question)],\n",
        "    \"question\": user_question,\n",
        "    \"rag_chain\": rag_chain,\n",
        "    \"retrieval_results\": None,\n",
        "    \"final_answer\": None,\n",
        "    \"human_approval\": None,\n",
        "    \"pending_review\": None,\n",
        "}\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"main-thread\"}}\n",
        "result = graph.invoke(initial_state, config=config)\n",
        "\n",
        "print(\"=\" * 80)\n",
        "print(\"FINAL ANSWER:\")\n",
        "print(\"=\" * 80)\n",
        "print(result[\"final_answer\"])\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "9d47aa4d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/markdown": [
              "The Transformer model operates primarily through attention mechanisms, which are utilized in three main ways: \\n1. **Encoder-decoder attention**: This allows the decoder to focus on different parts of the input sequence when generating outputs. \\n2. **Self-attention in the encoder**: This enables the model to weigh the significance of different words in the input for better representation. \\n3. **Self-attention in the decoder**: Similar to the encoder, this helps the decoder understand the context from the previously generated words in the output sequence. \\n\\nThe architecture consists of an encoder-decoder structure. The encoder comprises a stack of six identical layers, and each layer includes a multi-head self-attention mechanism and a position-wise fully connected feed-forward network. The decoder also has six layers but includes an additional attention layer for encoder-decoder attention. Both the encoder and decoder use residual connections and layer normalization, facilitating effective training and faster convergence. \\n\\nTransformers excel at sequence transduction tasks, such as machine translation, due to their ability to process sequences in parallel, effectively handling long-range dependencies, and outperforming traditional Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) in these applications. \n",
              "\n",
              "For detailed insights, refer to the paper \"Attention Is All You Need\" [source](https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf)."
            ],
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Markdown, display\n",
        "\n",
        "display(Markdown(result[\"final_answer\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b1545ec",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
